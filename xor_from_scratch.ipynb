{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "xor_from_scratch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaRaG4rBnao6",
        "colab_type": "text"
      },
      "source": [
        "## Using Back-propagation Algorithm with XOR data (from scratch)\n",
        "\n",
        "### What is XOR data: <br>\n",
        "It stands for exclusive OR, that is, it produces a true output results if one, and only one, of the inputs to the gate is true.\n",
        "\n",
        "**$ x_0 \\ x_1 \\ y$** <br>\n",
        "$0 \\ \\ \\  0 \\ \\ \\  0$ <br>\n",
        "$0 \\ \\ \\  1 \\ \\ \\  1$ <br>\n",
        "$1 \\ \\ \\  0 \\ \\ \\  1$<br>\n",
        "$1 \\ \\ \\  1 \\ \\ \\  0$<br>\n",
        "\n",
        "--------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bt1WHBN4nao-",
        "colab_type": "text"
      },
      "source": [
        "### Network Architecture\n",
        "\n",
        "#### This how I have the network. Any number of hidden layers and neurons in them can be added . Adding neurons/hidden layer MAY or MAY NOT improve the results.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=14Iw0rCAFHPsQjn93tFBwwnaoV0CuQc-3\" title=\"\" align=\"center\" width=\"70%\" height=\"70%\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeYCJWnHnapA",
        "colab_type": "text"
      },
      "source": [
        "### Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIG7kaSMnapD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yLHk34rnapL",
        "colab_type": "text"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9zjK7cpnapN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 0 is replaced by 0.1, 1 is replaced by 0.9\n",
        "# 0.9 as bias \n",
        "X = np.array([[0.1, 0.1, 0.9], [0.1, 0.9, 0.9],[0.9, 0.1,0.9], [0.9, 0.9,0.9]])\n",
        "\n",
        "Y = np.array([[0.1], [0.9],[0.9], [0.1]])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d4tBfbOnapR",
        "colab_type": "text"
      },
      "source": [
        "### Activation function and its derivative"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ql66QhQSnapS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid (x):\n",
        "    y = 1/(1 + np.exp(-x))\n",
        "    return y\n",
        "   \n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exiX5nLGnapW",
        "colab_type": "text"
      },
      "source": [
        "### Initializing weights\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB0VdwF6napY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ni = 3\n",
        "nh = 4\n",
        "no = 1\n",
        "\n",
        "weights1   = (2*np.random.random((nh,ni)) - 1)*0.01/2\n",
        "weights2   = (2*np.random.random((no,nh)) - 1)*0.01/2\n",
        "eta = 1\n",
        "\n",
        "\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hnxMg1Dnapb",
        "colab_type": "text"
      },
      "source": [
        "### Training the Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE-NcjTHnapc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eta = 1\n",
        "for epochs in range(5000):\n",
        "    for s in range(X.shape[0]):\n",
        "        ## forward propagation\n",
        "        hidden = sigmoid(np.dot(weights1, X[s])).reshape(-1, 1)\n",
        "        y = sigmoid(np.dot(weights2, hidden)).reshape(-1,1)\n",
        "        \n",
        "        ## backward propagation\n",
        "        delta_weights2 = np.dot(((Y[s] - y) * sigmoid_derivative(y)),hidden.reshape(-1, 1).T)\n",
        "        delta_weights1 = np.dot(((Y[s]-y) * sigmoid_derivative(y)*weights2.T * sigmoid_derivative(hidden)), X[s].reshape(1,3))\n",
        "\n",
        "        ## update weights\n",
        "        weights1 = weights1 + eta*delta_weights1\n",
        "        weights2 = weights2 + eta*delta_weights2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4BgKr-qnapf",
        "colab_type": "text"
      },
      "source": [
        "### Testing the Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H38sS4cznaph",
        "colab_type": "code",
        "outputId": "5dced0e1-f82d-475f-9397-b397f2101bf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "error = 0\n",
        "\n",
        "for s in range(X.shape[0]):\n",
        "    hidden = sigmoid(np.dot(weights1, X[s])).reshape(-1, 1)\n",
        "    y = sigmoid(np.dot(weights2, hidden)).reshape((-1,1))\n",
        "    \n",
        "    print('x:',X[s,:-1],' y:',y)\n",
        "    error += (Y[s] - y).dot(Y[s] - y)\n",
        "\n",
        "print('Error:',float(error)/4)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x: [0.1 0.1]  y: [[0.10035358]]\n",
            "x: [0.1 0.9]  y: [[0.89936202]]\n",
            "x: [0.9 0.1]  y: [[0.89924592]]\n",
            "x: [0.9 0.9]  y: [[0.10118398]]\n",
            "Error: 6.256206799288659e-07\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}